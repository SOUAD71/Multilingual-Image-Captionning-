# ğŸ–¼ï¸ Multilingual Image Captioning with BLIP & NLLB

## ğŸ“Œ Project Overview

This project implements an **intelligent multilingual image captioning system** capable of automatically generating a textual description from an image and translating it into multiple languages.

The system combines **Computer Vision**, **Natural Language Processing**, and **Machine Translation** using state-of-the-art deep learning models.

It is designed for **academic, research, and professional purposes** (Final Year Project / AI Demonstration).

---

## ğŸ¯ Objectives

- Automatically generate meaningful captions from images
- Translate generated captions into multiple languages
- Provide a clean and interactive user interface
- Implement a complete **Frontendâ€“Backendâ€“AI Models** architecture

---

## ğŸ§  Technologies Used

### ğŸ”¹ Backend
- Python 3
- FastAPI
- PyTorch
- Hugging Face Transformers
- BLIP (Salesforce Image Captioning)
- NLLB-200 (No Language Left Behind)
- Uvicorn

### ğŸ”¹ Frontend
- HTML5
- CSS3 (Modern UI & animations)
- JavaScript (Fetch API)

---

## ğŸŒ Supported Languages

- English (source language)
- French
- Spanish
- German
- Italian
- Portuguese
- Arabic
- Chinese
- Japanese
- Russian

---


